{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import nltk, re, pprint, json\n",
    "from nltk import word_tokenize\n",
    "# For plotting of data\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# For dataframes\n",
    "import pandas as pd\n",
    "# For Min-Max Normalisation\n",
    "from sklearn import preprocessing\n",
    "# For accessing file and folder paths\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "# For importing bigrams and trigrams from nltk\n",
    "from nltk.util import bigrams,trigrams\n",
    "\n",
    "# For Evaluation from PAN20 challenge\n",
    "import pan20_verif_evaluator as evaluator\n",
    "from time import perf_counter\n",
    "# Used for anlaysis of program\n",
    "import cProfile\n",
    "# Getting Date and Time information\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening Files and loading data\n",
    "def LoadAllData(path):\n",
    "    with open(path, 'r') as json_file:\n",
    "        JsonList = list(json_file)\n",
    "    return JsonList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function counts dissimilarity between two lists of freq dist - Performance slower than the below one\n",
    "def DissimilarityAlgorithm(FirstList,SecondList):\n",
    "    sumOfDissimilarValues = 0\n",
    "    countOfSimilarValues = 0\n",
    "    for firstItem in FirstList:\n",
    "        for secondItem in SecondList:            \n",
    "            if firstItem[0] == secondItem[0]:\n",
    "                # For items are similar, dissimilarities based on the frequencies\n",
    "                dissimilarValue = ((firstItem[1] - secondItem[1])*2/(firstItem[1] + secondItem[1]))**2\n",
    "                sumOfDissimilarValues = sumOfDissimilarValues + dissimilarValue\n",
    "                countOfSimilarValues = countOfSimilarValues + 1\n",
    "                break\n",
    "    # For all items\n",
    "    totalDissimilarValue = sumOfDissimilarValues + (len(FirstList)+len(SecondList)-countOfSimilarValues*2)*4\n",
    "    return totalDissimilarValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function evaluates POS-Tag ConditionalFrequency for the document with special modifications\n",
    "def EvaluatePOSTagConditionalFrequencyList(DocumentTagset, tag, profilelength):        \n",
    "    documentCfd=nltk.ConditionalFreqDist((tag,word) for (word,tag) in DocumentTagset)    \n",
    "    return documentCfd[tag].most_common(profilelength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function evaluates dissimilarity score for POS tags in the known and unknown document\n",
    "def EvaluatePosTagCount(DocumentTagset):\n",
    "    documentFreqDistOfPosTag = nltk.FreqDist(DocumentTagset)\n",
    "    documentCfdOfPosTag = nltk.FreqDist(tag for (word, tag) in documentFreqDistOfPosTag)\n",
    "    listOfMostCommonPosTagForDocument = documentCfdOfPosTag.most_common(100)\n",
    "    return listOfMostCommonPosTagForDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function evaluates character n-gram ConditionalFrequency for the document\n",
    "def EvaluateCharacterNGramConditionalFrequencyList(document, CharacterLength):\n",
    "    characterNGram = [word.lower() for word in [document[item:item+CharacterLength] for item in range(len(document)-CharacterLength+1)]]\n",
    "    return nltk.FreqDist(characterNGram).most_common(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function evaluates the dissimilarities values for all features \n",
    "# namely PosTag for Verb,Noun,Pronoun and Adjective ,\n",
    "# Word-N-Gram for N varies from 1 to 3 for profile length 100 and 200, \n",
    "# Character-N-Gram for N varies from 4 to 7 for profile length 100 and 200 and \n",
    "# POSCount for all possble POS\n",
    "# and stores in a dataframe and then combining to the ground truth values \n",
    "# whether the documents are written by same or different author \n",
    "\n",
    "def EvaluateDissimilaritiesFullDocumentSecondProcedure(TrainingDataList,GroundTruthDataList):\n",
    "    dissimilarityValues = []\n",
    "    for item in TrainingDataList:\n",
    "        \n",
    "        unknownDocument = json.loads(item)['pair'][1].replace('n\"t',' not').replace('N\"T',' NOT').replace('\"re',' are').replace('\"m',' am')\n",
    "        knownDocument = json.loads(item)['pair'][0].replace('n\"t',' not').replace('N\"T',' NOT').replace('\"re',' are').replace('\"m',' am')\n",
    "                \n",
    "        # Finding Tagset of documents\n",
    "        unknownDocumentTagset=nltk.pos_tag(word_tokenize(unknownDocument),tagset='universal')    \n",
    "        knownDocumentTagset=nltk.pos_tag(word_tokenize(knownDocument),tagset='universal')\n",
    "        \n",
    "        # Finding word-n-grams  \n",
    "        unknownDocumentForWord1Gram=nltk.FreqDist(nltk.word_tokenize(unknownDocument)).most_common(200)\n",
    "        knownDocumentForWord1Gram=nltk.FreqDist(nltk.word_tokenize(knownDocument)).most_common(200)\n",
    "        unknownDocumentForWord2Gram=nltk.FreqDist(list(bigrams(nltk.word_tokenize(unknownDocument)))).most_common(200)\n",
    "        knownDocumentForWord2Gram=nltk.FreqDist(list(bigrams(nltk.word_tokenize(knownDocument)))).most_common(200)\n",
    "        unknownDocumentForWord3Gram=nltk.FreqDist(list(trigrams(nltk.word_tokenize(unknownDocument)))).most_common(200)\n",
    "        knownDocumentForWord3Gram=nltk.FreqDist(list(trigrams(nltk.word_tokenize(knownDocument)))).most_common(200) \n",
    "        \n",
    "        # Finding character-n-grams\n",
    "        for charlength in range(4, 9):\n",
    "            globals()['unknownDocumentForCharacter%sGram' % charlength] = EvaluateCharacterNGramConditionalFrequencyList(unknownDocument, charlength)\n",
    "            globals()['knownDocumentForCharacter%sGram' % charlength] = EvaluateCharacterNGramConditionalFrequencyList(knownDocument, charlength)\n",
    "        \n",
    "        # Finding Features\n",
    "        features={            \n",
    "            'POS_TAG':{\n",
    "                'VERB':DissimilarityAlgorithm(EvaluatePOSTagConditionalFrequencyList(unknownDocumentTagset,'VERB',100),\n",
    "                                              EvaluatePOSTagConditionalFrequencyList(knownDocumentTagset,'VERB',100)),\n",
    "                'NOUN':DissimilarityAlgorithm(EvaluatePOSTagConditionalFrequencyList(unknownDocumentTagset,'NOUN',100),\n",
    "                                              EvaluatePOSTagConditionalFrequencyList(knownDocumentTagset,'NOUN',100)),\n",
    "                'PRON':DissimilarityAlgorithm(EvaluatePOSTagConditionalFrequencyList(unknownDocumentTagset,'PRON',100),\n",
    "                                                 EvaluatePOSTagConditionalFrequencyList(knownDocumentTagset,'PRON',100)),\n",
    "                'ADJ':DissimilarityAlgorithm(EvaluatePOSTagConditionalFrequencyList(unknownDocumentTagset,'ADJ',100),\n",
    "                                                   EvaluatePOSTagConditionalFrequencyList(knownDocumentTagset,'ADJ',100)),\n",
    "            },\n",
    "            'WORD_N_GRAMS':{\n",
    "                100:{\n",
    "                    1:DissimilarityAlgorithm(unknownDocumentForWord1Gram[:100],\n",
    "                                              knownDocumentForWord1Gram[:100]),\n",
    "                    2:DissimilarityAlgorithm(unknownDocumentForWord2Gram[:100],\n",
    "                                              knownDocumentForWord2Gram[:100]),\n",
    "                    3:DissimilarityAlgorithm(unknownDocumentForWord2Gram[:100],\n",
    "                                              knownDocumentForWord2Gram[:100])\n",
    "                },\n",
    "                200:{\n",
    "                    1:DissimilarityAlgorithm(unknownDocumentForWord1Gram[:200],\n",
    "                                              knownDocumentForWord1Gram[:200]),\n",
    "                    2:DissimilarityAlgorithm(unknownDocumentForWord2Gram[:200],\n",
    "                                              knownDocumentForWord2Gram[:200]),\n",
    "                    3:DissimilarityAlgorithm(unknownDocumentForWord3Gram[:200],\n",
    "                                              knownDocumentForWord3Gram[:200])\n",
    "                }\n",
    "                \n",
    "            },\n",
    "            'CHARACTER_N_GRAMS':{\n",
    "                100:{\n",
    "                    4:DissimilarityAlgorithm(EvaluateCharacterNGramConditionalFrequencyList(unknownDocument, 4)[:100],\n",
    "                                             EvaluateCharacterNGramConditionalFrequencyList(knownDocument, 4)[:100]),\n",
    "                    5:DissimilarityAlgorithm(EvaluateCharacterNGramConditionalFrequencyList(unknownDocument, 5)[:100],\n",
    "                                             EvaluateCharacterNGramConditionalFrequencyList(knownDocument, 5)[:100]),\n",
    "                    6:DissimilarityAlgorithm(EvaluateCharacterNGramConditionalFrequencyList(unknownDocument, 6)[:100],\n",
    "                                             EvaluateCharacterNGramConditionalFrequencyList(knownDocument, 6)[:100]),\n",
    "                    7:DissimilarityAlgorithm(EvaluateCharacterNGramConditionalFrequencyList(unknownDocument, 7)[:100],\n",
    "                                             EvaluateCharacterNGramConditionalFrequencyList(knownDocument, 7)[:100]),\n",
    "                    8:DissimilarityAlgorithm(EvaluateCharacterNGramConditionalFrequencyList(unknownDocument, 8)[:100],\n",
    "                                             EvaluateCharacterNGramConditionalFrequencyList(knownDocument, 8)[:100])\n",
    "                },\n",
    "                200:{\n",
    "                    4:DissimilarityAlgorithm(EvaluateCharacterNGramConditionalFrequencyList(unknownDocument, 4)[:200],\n",
    "                                             EvaluateCharacterNGramConditionalFrequencyList(knownDocument, 4)[:200]),\n",
    "                    5:DissimilarityAlgorithm(EvaluateCharacterNGramConditionalFrequencyList(unknownDocument, 5)[:200],\n",
    "                                             EvaluateCharacterNGramConditionalFrequencyList(knownDocument, 5)[:200]),\n",
    "                    6:DissimilarityAlgorithm(EvaluateCharacterNGramConditionalFrequencyList(unknownDocument, 6)[:200],\n",
    "                                             EvaluateCharacterNGramConditionalFrequencyList(knownDocument, 6)[:200]),\n",
    "                    7:DissimilarityAlgorithm(EvaluateCharacterNGramConditionalFrequencyList(unknownDocument, 7)[:200],\n",
    "                                             EvaluateCharacterNGramConditionalFrequencyList(knownDocument, 7)[:200]),\n",
    "                    8:DissimilarityAlgorithm(EvaluateCharacterNGramConditionalFrequencyList(unknownDocument, 8)[:200],\n",
    "                                             EvaluateCharacterNGramConditionalFrequencyList(knownDocument, 8)[:200])\n",
    "                }\n",
    "                \n",
    "            },\n",
    "            'POS_TAG_COUNT':DissimilarityAlgorithm(EvaluatePosTagCount(unknownDocumentTagset),\n",
    "                                                 EvaluatePosTagCount(knownDocumentTagset))\n",
    "            \n",
    "        }\n",
    "        \n",
    "        tempDissimilarityValues = (json.loads(item)['id'], features['POS_TAG']['VERB']\n",
    "                                   ,features['POS_TAG']['NOUN'],features['POS_TAG']['PRON'],\n",
    "                                   features['POS_TAG']['ADJ'],features['WORD_N_GRAMS'][100][1],\n",
    "                                   features['WORD_N_GRAMS'][100][2],features['WORD_N_GRAMS'][100][3],\n",
    "                                   features['CHARACTER_N_GRAMS'][100][4],features['CHARACTER_N_GRAMS'][100][5],\n",
    "                                   features['CHARACTER_N_GRAMS'][100][6],features['CHARACTER_N_GRAMS'][100][7],\n",
    "                                   features['CHARACTER_N_GRAMS'][100][8],features['WORD_N_GRAMS'][200][1],\n",
    "                                   features['WORD_N_GRAMS'][200][2],features['WORD_N_GRAMS'][200][3],\n",
    "                                   features['CHARACTER_N_GRAMS'][200][4],features['CHARACTER_N_GRAMS'][200][5],\n",
    "                                   features['CHARACTER_N_GRAMS'][200][6],features['CHARACTER_N_GRAMS'][200][7],\n",
    "                                   features['CHARACTER_N_GRAMS'][200][8],features['POS_TAG_COUNT'])\n",
    "        dissimilarityValues.append(tempDissimilarityValues)\n",
    "    \n",
    "    # DataFrame to add the list    \n",
    "    pairsDataFrame = pd.DataFrame(dissimilarityValues, columns=['id', 'PosTagVerbValue'\n",
    "                                                                ,'PosTagNounValue','PosTagPronounValue'\n",
    "                                                                ,'PosTagAdjectiveValue','Word1Gram100Value'\n",
    "                                                                ,'Word2Gram100Value','Word3Gram100Value'\n",
    "                                                                ,'Character4Gram100Value','Character5Gram100Value'\n",
    "                                                                ,'Character6Gram100Value','Character7Gram100Value'\n",
    "                                                                ,'Character8Gram100Value','Word1Gram200Value'\n",
    "                                                                ,'Word2Gram200Value','Word3Gram200Value'\n",
    "                                                                ,'Character4Gram200Value','Character5Gram200Value'\n",
    "                                                                ,'Character6Gram200Value','Character7Gram200Value'\n",
    "                                                                ,'Character8Gram200Value','PosTagCountValue'])\n",
    "\n",
    "    GroundTruthDataJsonList=[]        \n",
    "    \n",
    "    for item in GroundTruthDataList:\n",
    "        tempGroundTruthData = (json.loads(item)['id'], json.loads(item)['same'])\n",
    "        GroundTruthDataJsonList.append(tempGroundTruthData)\n",
    "    GroundTruthDataFrame=pd.DataFrame(GroundTruthDataJsonList, columns=['id','same'])    \n",
    "    completeDataFrame = pd.merge(pairsDataFrame, GroundTruthDataFrame, on='id')\n",
    "     \n",
    "    return completeDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get average of SimilarityValues For a column grouped by column 'same'\n",
    "# Provides normalised value for false and true\n",
    "def GetNormalisedAverageSimilarityValuesForColumn(InputDataFrame,SelectedColumn,MinMaxValues):\n",
    "    dissimilarityValues = InputDataFrame[[SelectedColumn]].values.astype(float) #returns a numpy array\n",
    "    newDissimilarityValues=np.append(dissimilarityValues, MinMaxValues)\n",
    "    newDissimilarityValues=newDissimilarityValues.reshape(len(newDissimilarityValues),1)\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    normalisedDissimilarityValues = min_max_scaler.fit_transform(newDissimilarityValues)\n",
    "    normalisedDataFrame=pd.DataFrame(normalisedDissimilarityValues,columns=['NormalisedValue'])\n",
    "    normalisedDataFrame.drop(normalisedDataFrame.tail(2).index,inplace=True)\n",
    "    normalisedDataFrame['id']= pd.DataFrame(InputDataFrame['id'])\n",
    "    normalisedDataFrame['SimilarityValue'] = 1-pd.DataFrame(normalisedDissimilarityValues)\n",
    "    normalisedDataFrame['same']=pd.DataFrame(InputDataFrame['same'])    \n",
    "    outputList=pd.DataFrame(normalisedDataFrame.groupby(['same']).mean()).values.tolist()    \n",
    "    return outputList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function transform unnormalised dissimilarity values to normalised similarity value\n",
    "# For normalisation, min-max normalisation is used\n",
    "# For min-max normalisation as minimum and maximum value, we are taking from both Training and Test data \n",
    "# From training set, we are taking two thresholding values. First from the similarity values of the same author pairs and second from the different author pairs \n",
    "# And this function returns Json List which will be used to generate ansers.jsonl file\n",
    "\n",
    "def DataTransformation(TestDataFrame,ColumnToBeNormalised,TrainingDataFrame):    \n",
    "    # Tuple to Dataframe        \n",
    "    MinMaxValues=[]\n",
    "    MinMaxValues.append((TrainingDataFrame[ColumnToBeNormalised].min(),TrainingDataFrame[ColumnToBeNormalised].max()))\n",
    "    NormalisedAverageSimilarityValues=GetNormalisedAverageSimilarityValuesForColumn(TrainingDataFrame,ColumnToBeNormalised,MinMaxValues)\n",
    "    \n",
    "    dissimilarityValues = TestDataFrame[[ColumnToBeNormalised]].values.astype(float) #returns a numpy array\n",
    "    newDissimilarityValues=np.append(dissimilarityValues, MinMaxValues)\n",
    "    newDissimilarityValues=newDissimilarityValues.reshape(len(newDissimilarityValues),1) #Reshaping the dimension\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    normalisedDissimilarityValues = min_max_scaler.fit_transform(newDissimilarityValues)\n",
    "    \n",
    "    normalisedDataFrame=pd.DataFrame(normalisedDissimilarityValues,columns=['NormalisedValue'])\n",
    "    normalisedDataFrame.drop(normalisedDataFrame.tail(2).index,inplace=True)\n",
    "    normalisedDataFrame['id']= pd.DataFrame(TestDataFrame['id'])\n",
    "    normalisedDataFrame['SimilarityValue'] = 1-pd.DataFrame(normalisedDissimilarityValues)\n",
    "    \n",
    "    normalisedValueForSameAuthor=NormalisedAverageSimilarityValues[0][0]\n",
    "    normalisedValueForDifferentAuthor=NormalisedAverageSimilarityValues[0][1]\n",
    "    \n",
    "    normalisedDataFrame['NewSimilarityValue'] = normalisedDataFrame['SimilarityValue']     \n",
    "    normalisedDataFrame.loc[((normalisedDataFrame['SimilarityValue'] >= normalisedValueForSameAuthor) \n",
    "                             & (normalisedDataFrame['SimilarityValue'] <= normalisedValueForDifferentAuthor)),'NewSimilarityValue'] = 0.5 \n",
    "    \n",
    "    normalisedDataFrame.loc[((normalisedDataFrame['SimilarityValue'] > normalisedValueForDifferentAuthor) \n",
    "                             & (normalisedDataFrame['SimilarityValue'] < 0.5)),'NewSimilarityValue'] = 1 - normalisedDataFrame['SimilarityValue']\n",
    "    \n",
    "    \n",
    "    newIndex = ['id', 'NewSimilarityValue']\n",
    "    normalisedDataFrame=normalisedDataFrame.reindex(columns=newIndex)    \n",
    "    normalizedJsonList=[]\n",
    "    for row in normalisedDataFrame.itertuples():\n",
    "        temporaryTuple = {}\n",
    "        temporaryTuple['id'] = row[1]\n",
    "        temporaryTuple['value'] =row[2]\n",
    "        normalizedJsonList.append(temporaryTuple)\n",
    "    return normalizedJsonList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate groundtruth in Json list which will be \n",
    "# later be used to used to generate truth.jsonl\n",
    "# Only used when part of training or test data is used\n",
    "def GenerateTruth(InputDataframe):    \n",
    "    # Tuple to Dataframe        \n",
    "    normalizedJsonList=[]\n",
    "    for row in InputDataframe.itertuples():\n",
    "        temporaryTuple = {}\n",
    "        temporaryTuple['id'] = row[1]\n",
    "        temporaryTuple['same'] =row[2]\n",
    "        normalizedJsonList.append(temporaryTuple)\n",
    "    return normalizedJsonList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create JSONL file depending upon data.\n",
    "# Input JSON List\n",
    "# Output JSONL file\n",
    "def CreateJSONLFiles(folderPath,fileName, data):\n",
    "    if not os.path.exists(folderPath):\n",
    "        os.makedirs(folderPath)\n",
    "    with open(folderPath+'/'+fileName, 'w') as outfile:\n",
    "        for entry in data:\n",
    "            json.dump(entry,outfile)\n",
    "            outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class files to store the path for truth.jsonl, answers.jsonl and for output evaluation file\n",
    "class EvaluatorArg:\n",
    "    i = \"input\"\n",
    "    a = \"answers\"\n",
    "    o = \"output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamically changing input, answers, output path for EvaluatorArg class\n",
    "def CreateClass(feature):\n",
    "    EvaluatorArg.i = InputPathForTruthTest\n",
    "    EvaluatorArg.a = os.path.join(Outputpath, feature,'Test')\n",
    "    EvaluatorArg.o = os.path.join(Outputpath, feature,'Test')\n",
    "    return EvaluatorArg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation for different type of Feature for either training, validation or test phase\n",
    "def EvaluationTypeForDifferentFeatures(InputDataFrame,Feature,Type,TrainingDataFrame):\n",
    "    EvaluatorArgPath = CreateClass(Feature)\n",
    "    CreateJSONLFiles(EvaluatorArgPath.a,'answers.jsonl',DataTransformation(InputDataFrame,Feature,TrainingDataFrame))\n",
    "    evaluator.main(EvaluatorArgPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation of Dissimilarity Algorithm for different length of datapoints\n",
    "# If Length is 0, then full dataset would be taken into consideration, \n",
    "# else specified length would be taken into consideration for training phase \n",
    "# with 10% of length validation phase and test phase\n",
    "\n",
    "def EvaluationOfDissimilarityAlgorithm(Length):\n",
    "    \n",
    "    if ((int(Length))==0):\n",
    "        # dissimilarityTrainingDataFrame=EvaluateDissimilaritiesFullDocumentSecondProcedure(TrainingJsonlist,GroundTruthTrainingJsonlist)  \n",
    "        dissimilarityTestDataFrame=EvaluateDissimilaritiesFullDocumentSecondProcedure(TestJsonlist,GroundTruthTestJsonlist) \n",
    "        \n",
    "    else:\n",
    "        tempLength=int(Length/2)        \n",
    "        newLength=23670+tempLength+1\n",
    "        testLength=int(0.1*Length)+1\n",
    "        \n",
    "        dissimilarityTrainingDataFrame=EvaluateDissimilaritiesFullDocumentSecondProcedure(TrainingJsonlist[0:tempLength]+TrainingJsonlist[23670:newLength]\n",
    "                                                                                          ,GroundTruthTrainingJsonlist[0:tempLength]+GroundTruthTrainingJsonlist[23670:newLength])\n",
    "        dissimilarityTestDataFrame=EvaluateDissimilaritiesFullDocumentSecondProcedure(TestJsonlist[0:testLength],GroundTruthTestJsonlist[0:testLength]) \n",
    "        \n",
    "   \n",
    "    # Test Dataset\n",
    "    groundTruthTestDataFrame = dissimilarityTestDataFrame[['id', 'same']]\n",
    "    modifiedDissimilarityTestDataFrame=dissimilarityTestDataFrame.loc[:, dissimilarityTestDataFrame.columns != 'same']\n",
    "    CreateJSONLFiles(InputPathForTruthTest,'truth.jsonl',GenerateTruth(groundTruthTestDataFrame))  \n",
    "    \n",
    "    \n",
    "    tempDataFrame=pd.DataFrame(dissimilarityTestDataFrame.loc[:, dissimilarityTestDataFrame.columns != 'id'])\n",
    "    columnsOfDissimilarityDataFrame=pd.DataFrame(tempDataFrame.loc[:, tempDataFrame.columns != 'same']).columns\n",
    "    columnsOfDissimilarityDataFrame    \n",
    "\n",
    "    for column in columnsOfDissimilarityDataFrame:        \n",
    "        print('Evaluation for ' + column +'  for Test Data Starts')\n",
    "        EvaluationTypeForDifferentFeatures(dissimilarityTestDataFrame,column,'Test',dissimilarityTrainingDataFrame)\n",
    "        print('Evaluation for ' + column +'  for Test Data Ends')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Paths to be set\n",
    "RootPath='./Datasets'\n",
    "Path=os.path.join(RootPath, 'pan20-authorship-verification','DissimilarityMethod')\n",
    "InputPathForTruthTest=os.path.join(Path, 'Output','Test')\n",
    "RootPath='./Datasets'\n",
    "Path = os.path.join(RootPath, 'pan20-authorship-verification', 'DissimilarityMethod')\n",
    "Outputpath=os.path.join(RootPath, 'pan20-authorship-verification', 'DissimilarityMethod','Output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading of data local path\n",
    "TrainingJsonlist=LoadAllData(os.path.join(Path, 'training','pairs.jsonl'))\n",
    "GroundTruthTrainingJsonlist=LoadAllData(os.path.join(Path, 'training','truth.jsonl'))\n",
    "TestJsonlist=LoadAllData(os.path.join(Path, 'test','pairs.jsonl'))\n",
    "GroundTruthTestJsonlist=LoadAllData(os.path.join(Path, 'test','truth.jsonl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entry Point of the Program to be called after loading of data\n",
    "def main(length): \n",
    "    print('Evaluation for all training datapoints Starts: ',datetime.now())\n",
    "    startAlgorithmAndEvaluation=perf_counter()\n",
    "    EvaluationOfDissimilarityAlgorithm(length)\n",
    "    durationOfAlgorithmAndEvaluation=perf_counter() - startAlgorithmAndEvaluation\n",
    "    print('Time taken: '+ format(durationOfAlgorithmAndEvaluation))\n",
    "    print('Evaluation for all training datapoints Ends: ',datetime.now())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for all training datapoints Starts:  2020-09-21 21:03:52.299751\n",
      "Evaluation for PosTagVerbValue  for Test Data Starts\n",
      "-> 2 problems in ground truth\n",
      "-> 2 solutions explicitly proposed\n",
      "{'auc': 0.0, 'c@1': 1.0, 'f_05_u': 1.0, 'F1': 1.0, 'overall': 0.75}\n",
      "Evaluation for PosTagVerbValue  for Test Data Ends\n",
      "Evaluation for PosTagNounValue  for Test Data Starts\n",
      "-> 2 problems in ground truth\n",
      "-> 2 solutions explicitly proposed\n",
      "{'auc': 0.0, 'c@1': 1.0, 'f_05_u': 1.0, 'F1': 1.0, 'overall': 0.75}\n",
      "Evaluation for PosTagNounValue  for Test Data Ends\n",
      "Evaluation for PosTagPronounValue  for Test Data Starts\n",
      "-> 2 problems in ground truth\n",
      "-> 2 solutions explicitly proposed\n",
      "{'auc': 0.0, 'c@1': 0.0, 'f_05_u': 1.0, 'F1': 0.0, 'overall': 0.25}\n",
      "Evaluation for PosTagPronounValue  for Test Data Ends\n",
      "Evaluation for PosTagAdjectiveValue  for Test Data Starts\n",
      "-> 2 problems in ground truth\n",
      "-> 2 solutions explicitly proposed\n",
      "{'auc': 0.0, 'c@1': 0.75, 'f_05_u': 1.0, 'F1': 1.0, 'overall': 0.688}\n",
      "Evaluation for PosTagAdjectiveValue  for Test Data Ends\n",
      "Evaluation for Word1Gram100Value  for Test Data Starts\n",
      "-> 2 problems in ground truth\n",
      "-> 2 solutions explicitly proposed\n",
      "{'auc': 0.0, 'c@1': 0.5, 'f_05_u': 0.833, 'F1': 0.667, 'overall': 0.5}\n",
      "Evaluation for Word1Gram100Value  for Test Data Ends\n",
      "Evaluation for Word2Gram100Value  for Test Data Starts\n",
      "-> 2 problems in ground truth\n",
      "-> 2 solutions explicitly proposed\n",
      "{'auc': 0.0, 'c@1': 1.0, 'f_05_u': 1.0, 'F1': 1.0, 'overall': 0.75}\n",
      "Evaluation for Word2Gram100Value  for Test Data Ends\n",
      "Evaluation for Word3Gram100Value  for Test Data Starts\n",
      "-> 2 problems in ground truth\n",
      "-> 2 solutions explicitly proposed\n",
      "{'auc': 0.0, 'c@1': 1.0, 'f_05_u': 1.0, 'F1': 1.0, 'overall': 0.75}\n",
      "Evaluation for Word3Gram100Value  for Test Data Ends\n",
      "Evaluation for Character4Gram100Value  for Test Data Starts\n",
      "-> 2 problems in ground truth\n",
      "-> 2 solutions explicitly proposed\n",
      "{'auc': 0.0, 'c@1': 0.5, 'f_05_u': 0.833, 'F1': 0.667, 'overall': 0.5}\n",
      "Evaluation for Character4Gram100Value  for Test Data Ends\n",
      "Evaluation for Character5Gram100Value  for Test Data Starts\n",
      "-> 2 problems in ground truth\n",
      "-> 2 solutions explicitly proposed\n",
      "{'auc': 0.0, 'c@1': 0.5, 'f_05_u': 0.833, 'F1': 0.667, 'overall': 0.5}\n",
      "Evaluation for Character5Gram100Value  for Test Data Ends\n",
      "Evaluation for Character6Gram100Value  for Test Data Starts\n",
      "-> 2 problems in ground truth\n",
      "-> 2 solutions explicitly proposed\n",
      "{'auc': 0.0, 'c@1': 0.5, 'f_05_u': 0.833, 'F1': 0.667, 'overall': 0.5}\n",
      "Evaluation for Character6Gram100Value  for Test Data Ends\n",
      "Evaluation for Character7Gram100Value  for Test Data Starts\n",
      "-> 2 problems in ground truth\n",
      "-> 2 solutions explicitly proposed\n",
      "{'auc': 0.0, 'c@1': 1.0, 'f_05_u': 1.0, 'F1': 1.0, 'overall': 0.75}\n",
      "Evaluation for Character7Gram100Value  for Test Data Ends\n",
      "Evaluation for Character8Gram100Value  for Test Data Starts\n",
      "-> 2 problems in ground truth\n",
      "-> 2 solutions explicitly proposed\n",
      "{'auc': 0.0, 'c@1': 1.0, 'f_05_u': 1.0, 'F1': 1.0, 'overall': 0.75}\n",
      "Evaluation for Character8Gram100Value  for Test Data Ends\n",
      "Evaluation for Word1Gram200Value  for Test Data Starts\n",
      "-> 2 problems in ground truth\n",
      "-> 2 solutions explicitly proposed\n",
      "{'auc': 0.0, 'c@1': 1.0, 'f_05_u': 1.0, 'F1': 1.0, 'overall': 0.75}\n",
      "Evaluation for Word1Gram200Value  for Test Data Ends\n",
      "Evaluation for Word2Gram200Value  for Test Data Starts\n",
      "-> 2 problems in ground truth\n",
      "-> 2 solutions explicitly proposed\n",
      "{'auc': 0.0, 'c@1': 1.0, 'f_05_u': 1.0, 'F1': 1.0, 'overall': 0.75}\n",
      "Evaluation for Word2Gram200Value  for Test Data Ends\n",
      "Evaluation for Word3Gram200Value  for Test Data Starts\n",
      "-> 2 problems in ground truth\n",
      "-> 2 solutions explicitly proposed\n",
      "{'auc': 0.0, 'c@1': 1.0, 'f_05_u': 1.0, 'F1': 1.0, 'overall': 0.75}\n",
      "Evaluation for Word3Gram200Value  for Test Data Ends\n",
      "Evaluation for Character4Gram200Value  for Test Data Starts\n",
      "-> 2 problems in ground truth\n",
      "-> 2 solutions explicitly proposed\n",
      "{'auc': 0.0, 'c@1': 0.5, 'f_05_u': 0.833, 'F1': 0.667, 'overall': 0.5}\n",
      "Evaluation for Character4Gram200Value  for Test Data Ends\n",
      "Evaluation for Character5Gram200Value  for Test Data Starts\n",
      "-> 2 problems in ground truth\n",
      "-> 2 solutions explicitly proposed\n",
      "{'auc': 0.0, 'c@1': 0.5, 'f_05_u': 0.833, 'F1': 0.667, 'overall': 0.5}\n",
      "Evaluation for Character5Gram200Value  for Test Data Ends\n",
      "Evaluation for Character6Gram200Value  for Test Data Starts\n",
      "-> 2 problems in ground truth\n",
      "-> 2 solutions explicitly proposed\n",
      "{'auc': 0.0, 'c@1': 0.5, 'f_05_u': 0.833, 'F1': 0.667, 'overall': 0.5}\n",
      "Evaluation for Character6Gram200Value  for Test Data Ends\n",
      "Evaluation for Character7Gram200Value  for Test Data Starts\n",
      "-> 2 problems in ground truth\n",
      "-> 2 solutions explicitly proposed\n",
      "{'auc': 0.0, 'c@1': 1.0, 'f_05_u': 1.0, 'F1': 1.0, 'overall': 0.75}\n",
      "Evaluation for Character7Gram200Value  for Test Data Ends\n",
      "Evaluation for Character8Gram200Value  for Test Data Starts\n",
      "-> 2 problems in ground truth\n",
      "-> 2 solutions explicitly proposed\n",
      "{'auc': 0.0, 'c@1': 1.0, 'f_05_u': 1.0, 'F1': 1.0, 'overall': 0.75}\n",
      "Evaluation for Character8Gram200Value  for Test Data Ends\n",
      "Evaluation for PosTagCountValue  for Test Data Starts\n",
      "-> 2 problems in ground truth\n",
      "-> 2 solutions explicitly proposed\n",
      "{'auc': 0.0, 'c@1': 1.0, 'f_05_u': 1.0, 'F1': 1.0, 'overall': 0.75}\n",
      "Evaluation for PosTagCountValue  for Test Data Ends\n",
      "Time taken: 86.85449601709843\n",
      "Evaluation for all training datapoints Ends:  2020-09-21 21:05:19.154516\n"
     ]
    }
   ],
   "source": [
    "# Run this cell to run over all data set\n",
    "main(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
